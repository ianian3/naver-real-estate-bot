"""
ë„¤ì´ë²„ ë¶€ë™ì‚° ë¸Œë¼ìš°ì € ìë™í™” ìŠ¤í¬ë˜í¼ (Playwright)
Tampermonkey ìŠ¤í¬ë¦½íŠ¸ ë¡œì§ì„ Pythonìœ¼ë¡œ ì¬êµ¬í˜„
"""

import asyncio
import time
import re
from typing import List, Dict, Optional, Tuple
from playwright.async_api import async_playwright, Page, Browser
import pandas as pd


# ë„¤ì´ë²„ ë¶€ë™ì‚° ê¸°ë³¸ URL
NAVER_REAL_ESTATE_URL = "https://new.land.naver.com"


class NaverRealEstateScraper:
    """ë„¤ì´ë²„ ë¶€ë™ì‚° ë¸Œë¼ìš°ì € ìë™í™” ìŠ¤í¬ë˜í¼"""
    
    def __init__(self, headless: bool = False):
        """
        Args:
            headless: Trueë©´ ë¸Œë¼ìš°ì € UI ì—†ì´ ì‹¤í–‰
        """
        self.headless = headless
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
    
    async def start(self):
        """ë¸Œë¼ìš°ì € ì‹œì‘"""
        playwright = await async_playwright().start()
        self.browser = await playwright.chromium.launch(headless=self.headless)
        self.page = await self.browser.new_page()
        
        # User Agent ì„¤ì •
        await self.page.set_extra_http_headers({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        
        print("âœ“ ë¸Œë¼ìš°ì € ì‹œì‘ë¨")
    
    async def close(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ"""
        if self.browser:
            await self.browser.close()
            print("âœ“ ë¸Œë¼ìš°ì € ì¢…ë£Œë¨")
    
    async def navigate_to_complex(self, complex_no: str) -> bool:
        """
        íŠ¹ì • ë‹¨ì§€ í˜ì´ì§€ë¡œ ì´ë™
        
        Args:
            complex_no: ë‹¨ì§€ ë²ˆí˜¸ (ì˜ˆ: "180280")
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        url = f"{NAVER_REAL_ESTATE_URL}/complexes/{complex_no}"
        
        try:
            print(f"ğŸ“ í˜ì´ì§€ ì´ë™ ì¤‘: {url}")
            await self.page.goto(url, wait_until='networkidle', timeout=30000)
            
            # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
            await self.page.wait_for_selector('#complexTitle', timeout=10000)
            
            # ë‹¨ì§€ëª… í™•ì¸
            complex_name = await self.page.locator('#complexTitle').inner_text()
            print(f"âœ“ ë‹¨ì§€ ë¡œë“œ ì™„ë£Œ: {complex_name}")
            
            return True
            
        except Exception as e:
            print(f"âŒ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    async def scroll_article_list(self, max_scrolls: int = 10):
        """
        ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ìŠ¤í¬ë¡¤í•˜ì—¬ ëª¨ë“  ë°ì´í„° ë¡œë“œ
        
        Args:
            max_scrolls: ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜
        """
        try:
            # ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ì˜ì—­ ì°¾ê¸°
            article_list_selector = '#articleListArea'
            await self.page.wait_for_selector(article_list_selector, timeout=10000)
            
            print("ğŸ“œ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ìŠ¤í¬ë¡¤ ì¤‘...")
            
            for i in range(max_scrolls):
                # ìŠ¤í¬ë¡¤ ì‹¤í–‰
                await self.page.evaluate('''
                    () => {
                        const listArea = document.querySelector('#articleListArea');
                        if (listArea) {
                            listArea.scrollTop = listArea.scrollHeight;
                        }
                    }
                ''')
                
                await asyncio.sleep(1)  # ë°ì´í„° ë¡œë“œ ëŒ€ê¸°
            
            print(f"âœ“ ìŠ¤í¬ë¡¤ ì™„ë£Œ ({max_scrolls}íšŒ)")
            
        except Exception as e:
            print(f"âš  ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def extract_listings(self) -> pd.DataFrame:
        """
        ë§¤ë¬¼ ë°ì´í„° ì¶”ì¶œ (Tampermonkey ë¡œì§ ì¬í˜„)
        
        Returns:
            DataFrame with columns: ë©´ì íƒ€ì…, ì „ìš©ë©´ì , ê±°ë˜ìœ í˜•, ì¸µ, ì¸µìˆ˜, ë°©í–¥, ê°€ê²©, ë³´ì¦ê¸ˆ, spec
        """
        try:
            # JavaScriptë¡œ DOMì—ì„œ ë°ì´í„° ì¶”ì¶œ
            listings_data = await self.page.evaluate('''
                () => {
                    const listings = [];
                    const articles = document.querySelectorAll('#articleListArea > div');
                    
                    articles.forEach(article => {
                        try {
                            // ë©´ì  ë° ì¸µìˆ˜ ì •ë³´
                            const specText = article.querySelector('.info_area .line .spec');
                            if (!specText) return;
                            
                            const aptInfo = specText.innerText.split(', ');
                            if (aptInfo.length < 2) return;
                            
                            const areaText = aptInfo[0];  // "103/84mÂ²"
                            const floorText = aptInfo[1]; // "5/10ì¸µ"
                            
                            // ì „ìš©ë©´ì  ì¶”ì¶œ
                            const areaMatch = areaText.match(/(\\d+)m/);
                            if (!areaMatch) return;
                            const exclusiveArea = parseFloat(areaMatch[1]);
                            
                            // ê±°ë˜ ìœ í˜• ë° ê°€ê²©
                            const tradeTypeElem = article.querySelector('.price_line .type');
                            const priceElem = article.querySelector('.price_line .price');
                            
                            if (!tradeTypeElem || !priceElem) return;
                            
                            const tradeType = tradeTypeElem.innerText.trim();
                            const priceText = priceElem.innerText.trim();
                            
                            // ê°€ê²© íŒŒì‹± (ì–µ/ë§Œì› â†’ ë§Œì›)
                            let price = 0;
                            if (priceText.includes('ì–µ')) {
                                const parts = priceText.replace(/,/g, '').split('ì–µ');
                                const eok = parseInt(parts[0]) || 0;
                                const man = parts[1] ? parseInt(parts[1].replace(/[^0-9]/g, '')) : 0;
                                price = eok * 10000 + man;
                            } else {
                                price = parseInt(priceText.replace(/[^0-9]/g, '')) || 0;
                            }
                            
                            // íŠ¹ì´ì‚¬í•­ (ì„¸ì•ˆê³ , ì˜¬ìˆ˜ë¦¬ ë“±)
                            const specElem = article.querySelector('.info_area > p:nth-child(2) > span');
                            const spec = specElem ? specElem.innerText.trim() : '';
                            
                            // ë°©í–¥ (ì—†ì„ ìˆ˜ ìˆìŒ)
                            const direction = '';
                            
                            listings.push({
                                area_text: areaText,
                                exclusive_area: exclusiveArea,
                                trade_type: tradeType,
                                floor: floorText,
                                price_text: priceText,
                                price: price,
                                spec: spec,
                                direction: direction
                            });
                            
                        } catch (e) {
                            console.error('ë§¤ë¬¼ íŒŒì‹± ì˜¤ë¥˜:', e);
                        }
                    });
                    
                    return listings;
                }
            ''')
            
            # DataFrame ë³€í™˜
            if not listings_data:
                print("âš  ì¶”ì¶œëœ ë§¤ë¬¼ ì—†ìŒ")
                return pd.DataFrame()
            
            # Python DataFrameìœ¼ë¡œ ë³€í™˜
            df_list = []
            for item in listings_data:
                # ì¸µìˆ˜ ì¶”ì¶œ
                floor_match = re.search(r'(\d+)/', item['floor'])
                floor_num = int(floor_match.group(1)) if floor_match else 0
                
                # ë©´ì  íƒ€ì… ê²°ì • (59A, 84A)
                area = item['exclusive_area']
                if 56 <= area <= 62:
                    area_type = '59A'
                elif 81 <= area <= 87:
                    area_type = '84A'
                else:
                    area_type = f"{int(area)}A"
                
                # ê±°ë˜ ìœ í˜• ë³€í™˜
                trade_type_map = {
                    'ë§¤ë§¤': 'SALE',
                    'ì „ì„¸': 'LEASE',
                    'ì›”ì„¸': 'RENT'
                }
                trade_type = trade_type_map.get(item['trade_type'], 'SALE')
                
                listing = {
                    'ë©´ì íƒ€ì…': area_type,
                    'ì „ìš©ë©´ì ': area,
                    'ê±°ë˜ìœ í˜•': trade_type,
                    'ì¸µ': item['floor'],
                    'ì¸µìˆ˜': floor_num,
                    'ë°©í–¥': item['direction'],
                    'ê°€ê²©': item['price'] if trade_type == 'SALE' else 0,
                    'ë³´ì¦ê¸ˆ': item['price'] if trade_type == 'LEASE' else 0,
                    'spec': item['spec']
                }
                
                df_list.append(listing)
            
            df = pd.DataFrame(df_list)
            print(f"âœ“ ë§¤ë¬¼ {len(df)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
            
            return df
            
        except Exception as e:
            print(f"âŒ ë§¤ë¬¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    async def get_complex_info(self) -> Dict:
        """ë‹¨ì§€ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            complex_name = await self.page.locator('#complexTitle').inner_text()
            
            # ì£¼ì†Œ ì¶”ì¶œ (ìˆëŠ” ê²½ìš°)
            address = ""
            try:
                address_elem = await self.page.locator('#summaryInfo .complex_address').first
                address = await address_elem.inner_text()
            except:
                pass
            
            # URLì—ì„œ ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
            current_url = self.page.url
            match = re.search(r'/complexes/(\d+)', current_url)
            complex_no = match.group(1) if match else 'unknown'
            
            return {
                'ë‹¨ì§€ë²ˆí˜¸': complex_no,
                'ë‹¨ì§€ëª…': complex_name,
                'ì£¼ì†Œ': address,
                'ì„¸ëŒ€ìˆ˜': 0,  # API í˜¸ì¶œ í•„ìš”
                'ê±´ì¶•ë…„ë„': 2010,  # ê¸°ë³¸ê°’
                'ë©´ì ': 0,
            }
            
        except Exception as e:
            print(f"âŒ ë‹¨ì§€ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}


async def scrape_complex(complex_no: str, headless: bool = False) -> Tuple[Dict, pd.DataFrame, pd.DataFrame]:
    """
    ë‹¨ì§€ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (ì •ë³´ + ë§¤ë§¤ + ì „ì„¸)
    
    Args:
        complex_no: ë‹¨ì§€ ë²ˆí˜¸
        headless: ë¸Œë¼ìš°ì € headless ëª¨ë“œ
    
    Returns:
        (complex_info, sale_df, lease_df)
    """
    scraper = NaverRealEstateScraper(headless=headless)
    
    try:
        await scraper.start()
        
        # ë‹¨ì§€ í˜ì´ì§€ ì´ë™
        success = await scraper.navigate_to_complex(complex_no)
        if not success:
            return {}, pd.DataFrame(), pd.DataFrame()
        
        # ìŠ¤í¬ë¡¤í•˜ì—¬ ëª¨ë“  ë§¤ë¬¼ ë¡œë“œ
        await scraper.scroll_article_list(max_scrolls=10)
        
        # ë‹¨ì§€ ì •ë³´ ì¶”ì¶œ
        complex_info = await scraper.get_complex_info()
        
        # ë§¤ë¬¼ ë°ì´í„° ì¶”ì¶œ
        all_listings = await scraper.extract_listings()
        
        # ë§¤ë§¤/ì „ì„¸ ë¶„ë¦¬
        sale_df = all_listings[all_listings['ê±°ë˜ìœ í˜•'] == 'SALE'].copy() if not all_listings.empty else pd.DataFrame()
        lease_df = all_listings[all_listings['ê±°ë˜ìœ í˜•'] == 'LEASE'].copy() if not all_listings.empty else pd.DataFrame()
        
        print(f"\nâœ“ ìˆ˜ì§‘ ì™„ë£Œ: ë§¤ë§¤ {len(sale_df)}ê°œ, ì „ì„¸ {len(lease_df)}ê°œ")
        
        return complex_info, sale_df, lease_df
        
    finally:
        await scraper.close()


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_scraping():
    """ë¸Œë¼ìš°ì € ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    # í…ŒìŠ¤íŠ¸ ë‹¨ì§€: ì€ë§ˆì•„íŒŒíŠ¸ (180280)
    test_complex = '180280'
    
    print("=== ë¸Œë¼ìš°ì € ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ===\n")
    print(f"í…ŒìŠ¤íŠ¸ ë‹¨ì§€: {test_complex}\n")
    
    info, sale, lease = await scrape_complex(test_complex, headless=False)
    
    print("\n" + "="*60)
    print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼")
    print("="*60)
    print(f"\në‹¨ì§€ ì •ë³´:")
    for key, value in info.items():
        print(f"  {key}: {value}")
    
    if not sale.empty:
        print(f"\në§¤ë§¤ ë§¤ë¬¼ ({len(sale)}ê°œ):")
        print(sale[['ë©´ì íƒ€ì…', 'ì „ìš©ë©´ì ', 'ì¸µìˆ˜', 'ê°€ê²©', 'spec']].head(5))
    
    if not lease.empty:
        print(f"\nì „ì„¸ ë§¤ë¬¼ ({len(lease)}ê°œ):")
        print(lease[['ë©´ì íƒ€ì…', 'ì „ìš©ë©´ì ', 'ì¸µìˆ˜', 'ë³´ì¦ê¸ˆ', 'spec']].head(5))


if __name__ == "__main__":
    asyncio.run(test_scraping())
